
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="..">
      
      
      <link rel="icon" href="../icon.svg">
      <meta name="generator" content="mkdocs-1.5.2, mkdocs-material-9.1.21">
    
    
      
        <title>Execution - psiflow</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.eebd395e.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.ecc896b0.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/katex.min.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="teal">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#execution-definitions" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="psiflow" class="md-header__button md-logo" aria-label="psiflow" data-md-component="logo">
      
  <img src="../icon.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            psiflow
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Execution
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <div class="md-header__source">
        <a href="https://github.com/molmod/psiflow" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  

<nav class="md-nav md-nav--primary md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="psiflow" class="md-nav__button md-logo" aria-label="psiflow" data-md-component="logo">
      
  <img src="../icon.svg" alt="logo">

    </a>
    psiflow
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/molmod/psiflow" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        Overview
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Execution
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Execution
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#execution-definitions" class="md-nav__link">
    Execution definitions
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#configuration" class="md-nav__link">
    Configuration
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#setup" class="md-nav__link">
    Setup
  </a>
  
    <nav class="md-nav" aria-label="Setup">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#containerized" class="md-nav__link">
    Containerized
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#manual" class="md-nav__link">
    Manual
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


  <h1>Execution</h1>

<p>Psiflow makes it extremely easy to build
complex computational graphs that consist of
QM evaluations, model training, and a variety of phase space sampling algorithms, among others.
If your Python environment contains the required dependencies, you can execute any of the learning examples just like that:
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="gp">$ </span>python<span class="w"> </span>zeolite_reaction.py
</code></pre></div>
Model training, molecular dynamics, and reference evaluations will all get executed in separate processes; the main
Python script only used to resolve the computational directed acyclic graph (DAG) of tasks.
However, local execution is rather limiting because the evaluation of an average learning workflow requires
large amounts of several different computational resources.
For example, QM calculations typically require nodes with a large core count (64 or even 128)
and with sufficient memory, whereas model training and evaluation require one or more powerful
GPUs.
Because a single computer can never provide the computing power that is required to
execute such workflows, psiflow is intrinsically built to support distributed
and asynchronous execution across a large variety of resources (including most HPC and cloud infrastructure).
This means that while the entire online learning workflow is defined in a single Python script,
its execution is automatically performed on tens, hundreds, or even thousands of nodes.
Configuration of the execution resources is done using a single Python script; <code>config.py</code>.
It specifies the following parameters (among others)</p>
<ul>
<li>the number of cores to use for each CP2K singlepoint evaluation, as well as the specific OpenMP/MPI parallellization settings;</li>
<li>the project ID from Google Compute Engine, if applicable;</li>
<li>the computational resources to request in a single SLURM job, if applicable.
This includes walltime, core count, and memory, as well as e.g. the maximum number of molecular dynamics
simulations that can be executed in parallel in a single job;</li>
<li>the execution of specific <code>module load</code> or <code>source env/bin/activate</code> commands to ensure all the necessary environment variables are set.</li>
</ul>
<p>The execution parameters in the configuration script are strictly and deliberately kept separate
from the main Python script that defines the workflow, in line with Parsl's philosophy <em>write once, run anywhere</em>.
To execute the zeolite reaction example not on your local computer, but on remote compute resources
(e.g. the Frontier exascale system at OLCF), you simply have to <strong>pass the relevant psiflow configuration
file as an argument</strong>:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="gp">  $ </span>python<span class="w"> </span>my_workflow.py<span class="w"> </span>--psiflow-config<span class="w"> </span>frontier.py<span class="w">      </span><span class="c1"># executes exact same workflow on Frontier</span>
</code></pre></div>
<p>The following sections will explain in more detail how remote execution is configured.</p>
<div class="admonition note">
<p class="admonition-title">Parsl execution</p>
<p>Before you continue, we recommend going through the 
<a href="https://parsl.readthedocs.io/en/stable/userguide/execution.html">Parsl documentation on execution</a>
first in order to get acquainted with the <code>executor</code>, <code>provider</code>, and <code>launcher</code>
concepts.</p>
</div>
<h2 id="execution-definitions">Execution definitions</h2>
<p>The definition of all execution-side parameters happens in the psiflow configuration file.
Its contents are divided in so-called execution definitions, each of which specifies how and where
a certain type of calculation will be executed. Each definition accepts at least the following arguments:</p>
<ul>
<li><code>gpu: bool = False</code>: whether or not this calculation proceeds on the GPU</li>
<li><code>cores_per_worker: int = 1</code>: how many cores each individual calculation requires</li>
<li><code>max_walltime: float = None</code>: specifies a maximum duration of each calculation before it gets gracefully killed.</li>
<li><code>parsl_provider: parsl.providers.ExecutionProvider</code>: a Parsl provider which psiflow can use to get compute time.
For a <code>ClusterProvider</code>, this involves submitting a job to the queueing system; for a <code>GoogleCloudProvider</code>,
this involves provisioning and connecting to a node in the cloud; for a <code>LocalProvider</code>, this just means "use the resources
available on the current system". See <a href="https://parsl.readthedocs.io/en/stable/userguide/execution.html#execution-providers">this section</a>
in the Parsl documentation for more details.</li>
</ul>
<p>Psiflow introduces four different execution definitions:</p>
<ol>
<li><strong>model evaluation</strong>: this determines how and where the trainable models (i.e. <code>BaseModel</code> instances) are
executed. In addition to the common arguments above, it allows the user to specify a <code>simulation_engine</code>, with possible
values being <code>yaff</code> (slow, legacy) and <code>openmm</code> (faster, new in v2.0.0). Older versions additionally allowed users to
perform certain calculations in <code>float64</code> (which might be relevant when doing energy minimizations) but this has been
removed in v2.0.0; all calculations are now performed in <code>float32</code>.</li>
<li><strong>model training</strong>: this definition determines where models are trained. It is <em>forced</em> to have <code>gpu=True</code> because model training
is always performed on GPU (and in <code>float32</code>) anyway.</li>
<li><strong>reference evaluation</strong>: this determines how and where QM evaluations are performed. Because most (if not all) QM engines
rely on MPI (and sometimes OpenMP) to parallelize over multiple cores, it is possible to specify your own MPI command here.
It should be a function with a single argument, which returns (as string) the MPI command to use when executing a QM evaluation.
Its default value is the following <code>lambda</code> expression (for MPICH):
<div class="highlight"><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="n">mpi_command</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;mpirun -np </span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s1"> -bind-to core -rmk user -launcher fork&#39;</span>
</code></pre></div></li>
<li><strong>default execution</strong>: this determines where the lightweight/administrative operations get executed (dataset copying, basic numpy operations, ...).
Typically, this requires only a few cores and a few GBs of memory.</li>
</ol>
<h2 id="configuration">Configuration</h2>
<p>Let's illustrate how the execution definitions can be used to construct a psiflow configuration file.
Essentially, such files consist of a single <code>get_config()</code> method which should return a Parsl <code>Config</code> object
as well as a list of psiflow <code>ExecutionDefinition</code> instances as discussed above.
For simplicity, let us assume for now that all of the required compute resources are available locally,
which means we can use parsl's <code>LocalProvider</code> in the various definitions:
<div class="highlight"><span class="filename">local_htex.py</span><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="kn">from</span> <span class="nn">parsl.providers</span> <span class="kn">import</span> <span class="n">LocalProvider</span>
<a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a>
<a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a><span class="kn">from</span> <span class="nn">psiflow.execution</span> <span class="kn">import</span> <span class="n">Default</span><span class="p">,</span> <span class="n">ModelTraining</span><span class="p">,</span> <span class="n">ModelEvaluation</span><span class="p">,</span> \
<a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a>        <span class="n">ReferenceEvaluation</span><span class="p">,</span> <span class="n">generate_parsl_config</span>
<a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a>
<a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a>
<a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a><span class="n">default</span> <span class="o">=</span> <span class="n">Default</span><span class="p">()</span>                         <span class="c1"># subclass of ExecutionDefinition</span>
<a id="__codelineno-3-8" name="__codelineno-3-8" href="#__codelineno-3-8"></a><span class="n">model_evaluation</span> <span class="o">=</span> <span class="n">ModelEvaluation</span><span class="p">(</span>         <span class="c1"># subclass of ExecutionDefinition</span>
<a id="__codelineno-3-9" name="__codelineno-3-9" href="#__codelineno-3-9"></a>        <span class="n">parsl_provider</span><span class="o">=</span><span class="n">LocalProvider</span><span class="p">(),</span>
<a id="__codelineno-3-10" name="__codelineno-3-10" href="#__codelineno-3-10"></a>        <span class="n">cores_per_worker</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<a id="__codelineno-3-11" name="__codelineno-3-11" href="#__codelineno-3-11"></a>        <span class="n">max_walltime</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>                    <span class="c1"># in minutes!</span>
<a id="__codelineno-3-12" name="__codelineno-3-12" href="#__codelineno-3-12"></a>        <span class="n">simulation_engine</span><span class="o">=</span><span class="s1">&#39;openmm&#39;</span><span class="p">,</span>         <span class="c1"># or yaff; openmm is faster</span>
<a id="__codelineno-3-13" name="__codelineno-3-13" href="#__codelineno-3-13"></a>        <span class="n">gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>                       
<a id="__codelineno-3-14" name="__codelineno-3-14" href="#__codelineno-3-14"></a>        <span class="p">)</span>
<a id="__codelineno-3-15" name="__codelineno-3-15" href="#__codelineno-3-15"></a><span class="n">model_training</span> <span class="o">=</span> <span class="n">ModelTraining</span><span class="p">(</span>             <span class="c1"># subclass of ExecutionDefinition</span>
<a id="__codelineno-3-16" name="__codelineno-3-16" href="#__codelineno-3-16"></a>        <span class="n">parsl_provider</span><span class="o">=</span><span class="n">LocalProvider</span><span class="p">(),</span>     <span class="c1"># or SlurmProvider / GoogleCloudProvider / ...</span>
<a id="__codelineno-3-17" name="__codelineno-3-17" href="#__codelineno-3-17"></a>        <span class="n">gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-3-18" name="__codelineno-3-18" href="#__codelineno-3-18"></a>        <span class="n">max_walltime</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>                
<a id="__codelineno-3-19" name="__codelineno-3-19" href="#__codelineno-3-19"></a>        <span class="p">)</span>
<a id="__codelineno-3-20" name="__codelineno-3-20" href="#__codelineno-3-20"></a><span class="n">reference_evaluation</span> <span class="o">=</span> <span class="n">ReferenceEvaluation</span><span class="p">(</span> <span class="c1"># subclass of ExecutionDefinition</span>
<a id="__codelineno-3-21" name="__codelineno-3-21" href="#__codelineno-3-21"></a>        <span class="n">parsl_provider</span><span class="o">=</span><span class="n">LocalProvider</span><span class="p">(),</span>
<a id="__codelineno-3-22" name="__codelineno-3-22" href="#__codelineno-3-22"></a>        <span class="n">cores_per_worker</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
<a id="__codelineno-3-23" name="__codelineno-3-23" href="#__codelineno-3-23"></a>        <span class="n">max_walltime</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span>                    <span class="c1"># kill after this amount of time, in minutes</span>
<a id="__codelineno-3-24" name="__codelineno-3-24" href="#__codelineno-3-24"></a>        <span class="n">mpi_command</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;mpirun -np </span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s1"> -bind-to core -rmk user -launcher fork&#39;</span><span class="p">,</span>
<a id="__codelineno-3-25" name="__codelineno-3-25" href="#__codelineno-3-25"></a>        <span class="p">)</span>
<a id="__codelineno-3-26" name="__codelineno-3-26" href="#__codelineno-3-26"></a><span class="n">definitions</span> <span class="o">=</span> <span class="p">[</span>
<a id="__codelineno-3-27" name="__codelineno-3-27" href="#__codelineno-3-27"></a>        <span class="n">default</span><span class="p">,</span>
<a id="__codelineno-3-28" name="__codelineno-3-28" href="#__codelineno-3-28"></a>        <span class="n">model_evaluation</span><span class="p">,</span>
<a id="__codelineno-3-29" name="__codelineno-3-29" href="#__codelineno-3-29"></a>        <span class="n">model_training</span><span class="p">,</span>
<a id="__codelineno-3-30" name="__codelineno-3-30" href="#__codelineno-3-30"></a>        <span class="n">reference_evaluation</span><span class="p">,</span>
<a id="__codelineno-3-31" name="__codelineno-3-31" href="#__codelineno-3-31"></a>        <span class="p">]</span>
<a id="__codelineno-3-32" name="__codelineno-3-32" href="#__codelineno-3-32"></a>
<a id="__codelineno-3-33" name="__codelineno-3-33" href="#__codelineno-3-33"></a>
<a id="__codelineno-3-34" name="__codelineno-3-34" href="#__codelineno-3-34"></a><span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="n">path_internal</span><span class="p">):</span>
<a id="__codelineno-3-35" name="__codelineno-3-35" href="#__codelineno-3-35"></a>    <span class="n">config</span> <span class="o">=</span> <span class="n">generate_parsl_config</span><span class="p">(</span>
<a id="__codelineno-3-36" name="__codelineno-3-36" href="#__codelineno-3-36"></a>            <span class="n">path_internal</span><span class="p">,</span>
<a id="__codelineno-3-37" name="__codelineno-3-37" href="#__codelineno-3-37"></a>            <span class="n">definitions</span><span class="p">,</span>
<a id="__codelineno-3-38" name="__codelineno-3-38" href="#__codelineno-3-38"></a>            <span class="n">use_work_queue</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>           <span class="c1"># can improve the scheduling of jobs but also slows down</span>
<a id="__codelineno-3-39" name="__codelineno-3-39" href="#__codelineno-3-39"></a>            <span class="n">parsl_max_idletime</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
<a id="__codelineno-3-40" name="__codelineno-3-40" href="#__codelineno-3-40"></a>            <span class="n">parsl_retries</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>                <span class="c1"># retry at least once in case the error happened randomly</span>
<a id="__codelineno-3-41" name="__codelineno-3-41" href="#__codelineno-3-41"></a>            <span class="p">)</span>
<a id="__codelineno-3-42" name="__codelineno-3-42" href="#__codelineno-3-42"></a>    <span class="k">return</span> <span class="n">config</span><span class="p">,</span> <span class="n">definitions</span>
</code></pre></div>
These definitions imply that:</p>
<ul>
<li>molecular dynamics will be performed using the OpenMM engine, one two cores and one GPU,
and will be gracefully killed after 30 minutes;</li>
<li>model training is allowed to run for a maximum of 10 minutes;</li>
<li>reference QM evaluations will be performed using 6 cores per singlepoint, and with a specific MPI command.
If a singlepoint takes longer than 60 minutes, it is killed. No energy labels will be stored in the state,
and the corresponding FlowAtoms instance will have <code>reference_status = False</code>.</li>
</ul>
<p>The <code>get_config()</code> method takes a single argument (a cache directory shared by all compute resources) and builds a
Parsl <code>Config</code> based on the provided definitions and a few additional parameters, such the maximum number of retries
that Parsl may attempt for a specific task
(which can be useful e.g. when the cluster you're using contains a few faulty nodes).</p>
<h2 id="setup">Setup</h2>
<p>The main Python script will typically be executed on a local workstation or a login/compute node of a cluster;
this will be referred to as the <strong>submission side</strong>.
Because all nontrivial calculations are forwarded to the appropriate compute
resources as specified in the configuration script (see below), the submission side does
not actually do any work, and it is therefore trivial to set up. 
All that is required is a Python environment in which Parsl and psiflow are
available (and, optionally, <code>ndcctools</code> for better scheduling).
We recommend using
<a href="https://mamba.readthedocs.io/en/latest/installation.html#micromamba">micromamba</a>
-- a blazingly fast <code>conda</code> replacement -- to set this up:
<div class="highlight"><pre><span></span><code><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span class="gp">$ </span>micromamba<span class="w"> </span>create<span class="w"> </span>-p<span class="w"> </span>./psiflow_env<span class="w"> </span><span class="nv">ndcctools</span><span class="o">=</span><span class="m">7</span>.6.1<span class="w"> </span>-c<span class="w"> </span>conda-forge<span class="w"> </span>-y<span class="w"> </span><span class="nv">python</span><span class="o">=</span><span class="m">3</span>.9
<a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a><span class="gp">$ </span>micromamba<span class="w"> </span>activate<span class="w"> </span>./psiflow_env
<a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a><span class="gp">$ </span>pip<span class="w"> </span>install<span class="w"> </span>git+https://github.com/molmod/psiflow<span class="w">   </span><span class="c1"># installs Parsl + dependencies</span>
</code></pre></div>
Setting up the <strong>execution side</strong> is technically more challenging because it
needs to have working installations of (parallelized) CP2K, PLUMED, and GPU-enabled PyTorch.</p>
<h3 id="containerized">Containerized</h3>
<p>To alleviate users from having to go through all of the installation
shenanigans, psiflow provides all-inclusive containers which bundle all of its
dependencies into a portable entity --
a container image!
Whether you're executing your calculations on a high-memory node in a cluster
or using a GPU in google cloud, all that is required is a working <a href="https://www.docker.com/">Docker</a>
or <a href="https://apptainer.org/">Apptainer/Singularity</a> installation and you're good to go.
During task distribution, psiflow will automatically pull the relevant
container image from the
<a href="https://github.com/molmod/psiflow/pkgs/container/psiflow">GitHub Container Registry</a>
and execute its tasks inside the container at approximately bare metal
performance.</p>
<p>Containerized execution is possible locally, but is particularly useful when combined with
remote execution.
As an example of this, consider the following configuration:</p>
<p><div class="highlight"><span class="filename">vsc_hortense.py</span><pre><span></span><code><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span class="kn">from</span> <span class="nn">parsl.providers</span> <span class="kn">import</span> <span class="n">SlurmProvider</span>
<a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a><span class="kn">from</span> <span class="nn">parsl.launchers</span> <span class="kn">import</span> <span class="n">SimpleLauncher</span>
<a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a>
<a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a><span class="kn">from</span> <span class="nn">psiflow.execution</span> <span class="kn">import</span> <span class="n">Default</span><span class="p">,</span> <span class="n">ModelTraining</span><span class="p">,</span> <span class="n">ModelEvaluation</span><span class="p">,</span> \
<a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a>        <span class="n">ReferenceEvaluation</span><span class="p">,</span> <span class="n">generate_parsl_config</span>
<a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a><span class="kn">from</span> <span class="nn">psiflow.parsl_utils</span> <span class="kn">import</span> <span class="n">ContainerizedLauncher</span>
<a id="__codelineno-5-7" name="__codelineno-5-7" href="#__codelineno-5-7"></a>
<a id="__codelineno-5-8" name="__codelineno-5-8" href="#__codelineno-5-8"></a>
<a id="__codelineno-5-9" name="__codelineno-5-9" href="#__codelineno-5-9"></a><span class="c1"># The ContainerizedLauncher is a subclass of Parsl Launchers, which simply</span>
<a id="__codelineno-5-10" name="__codelineno-5-10" href="#__codelineno-5-10"></a><span class="c1"># wraps all commands to be executed inside a container.</span>
<a id="__codelineno-5-11" name="__codelineno-5-11" href="#__codelineno-5-11"></a><span class="c1"># The ORAS containers are downloaded from Github -- though it&#39;s best to cache</span>
<a id="__codelineno-5-12" name="__codelineno-5-12" href="#__codelineno-5-12"></a><span class="c1"># them beforehand (e.g. by executing &#39;apptainer exec &lt;uri&gt; pwd&#39;).</span>
<a id="__codelineno-5-13" name="__codelineno-5-13" href="#__codelineno-5-13"></a><span class="n">launcher_cpu</span> <span class="o">=</span> <span class="n">ContainerizedLauncher</span><span class="p">(</span>
<a id="__codelineno-5-14" name="__codelineno-5-14" href="#__codelineno-5-14"></a>        <span class="s1">&#39;docker://ghcr.io/molmod/psiflow:2.0.0-cuda11.8&#39;</span><span class="p">,</span>
<a id="__codelineno-5-15" name="__codelineno-5-15" href="#__codelineno-5-15"></a>        <span class="n">apptainer_or_singularity</span><span class="o">=</span><span class="s1">&#39;apptainer&#39;</span><span class="p">,</span>
<a id="__codelineno-5-16" name="__codelineno-5-16" href="#__codelineno-5-16"></a>        <span class="p">)</span>
<a id="__codelineno-5-17" name="__codelineno-5-17" href="#__codelineno-5-17"></a><span class="n">launcher_gpu</span> <span class="o">=</span> <span class="n">ContainerizedLauncher</span><span class="p">(</span>
<a id="__codelineno-5-18" name="__codelineno-5-18" href="#__codelineno-5-18"></a>        <span class="s1">&#39;docker://ghcr.io/molmod/psiflow:2.0.0-cuda11.8&#39;</span><span class="p">,</span>
<a id="__codelineno-5-19" name="__codelineno-5-19" href="#__codelineno-5-19"></a>        <span class="n">apptainer_or_singularity</span><span class="o">=</span><span class="s1">&#39;apptainer&#39;</span><span class="p">,</span>
<a id="__codelineno-5-20" name="__codelineno-5-20" href="#__codelineno-5-20"></a>        <span class="n">enable_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>            <span class="c1"># binds GPU in container</span>
<a id="__codelineno-5-21" name="__codelineno-5-21" href="#__codelineno-5-21"></a>        <span class="p">)</span>
<a id="__codelineno-5-22" name="__codelineno-5-22" href="#__codelineno-5-22"></a>
<a id="__codelineno-5-23" name="__codelineno-5-23" href="#__codelineno-5-23"></a><span class="n">default</span> <span class="o">=</span> <span class="n">Default</span><span class="p">(</span>
<a id="__codelineno-5-24" name="__codelineno-5-24" href="#__codelineno-5-24"></a>        <span class="n">cores_per_worker</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>         <span class="c1"># 8 / 4 = 2 workers per slurm job</span>
<a id="__codelineno-5-25" name="__codelineno-5-25" href="#__codelineno-5-25"></a>        <span class="n">parsl_provider</span><span class="o">=</span><span class="n">SlurmProvider</span><span class="p">(</span>
<a id="__codelineno-5-26" name="__codelineno-5-26" href="#__codelineno-5-26"></a>            <span class="n">partition</span><span class="o">=</span><span class="s1">&#39;cpu_rome&#39;</span><span class="p">,</span>
<a id="__codelineno-5-27" name="__codelineno-5-27" href="#__codelineno-5-27"></a>            <span class="n">account</span><span class="o">=</span><span class="s1">&#39;2022_050&#39;</span><span class="p">,</span>
<a id="__codelineno-5-28" name="__codelineno-5-28" href="#__codelineno-5-28"></a>            <span class="n">nodes_per_block</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>      <span class="c1"># each block fits on (less than) one node</span>
<a id="__codelineno-5-29" name="__codelineno-5-29" href="#__codelineno-5-29"></a>            <span class="n">cores_per_node</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>       <span class="c1"># number of cores per slurm job</span>
<a id="__codelineno-5-30" name="__codelineno-5-30" href="#__codelineno-5-30"></a>            <span class="n">init_blocks</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>          <span class="c1"># initialize a block at the start of the workflow</span>
<a id="__codelineno-5-31" name="__codelineno-5-31" href="#__codelineno-5-31"></a>            <span class="n">min_blocks</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>           <span class="c1"># always keep at least one block open</span>
<a id="__codelineno-5-32" name="__codelineno-5-32" href="#__codelineno-5-32"></a>            <span class="n">max_blocks</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>           <span class="c1"># do not use more than one block</span>
<a id="__codelineno-5-33" name="__codelineno-5-33" href="#__codelineno-5-33"></a>            <span class="n">walltime</span><span class="o">=</span><span class="s1">&#39;72:00:00&#39;</span><span class="p">,</span>    <span class="c1"># walltime per block</span>
<a id="__codelineno-5-34" name="__codelineno-5-34" href="#__codelineno-5-34"></a>            <span class="n">exclusive</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-5-35" name="__codelineno-5-35" href="#__codelineno-5-35"></a>            <span class="n">scheduler_options</span><span class="o">=</span><span class="s1">&#39;#SBATCH --clusters=dodrio</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="c1"># specify the cluster</span>
<a id="__codelineno-5-36" name="__codelineno-5-36" href="#__codelineno-5-36"></a>            <span class="n">launcher</span><span class="o">=</span><span class="n">launcher_cpu</span><span class="p">,</span>  <span class="c1"># no GPU needed</span>
<a id="__codelineno-5-37" name="__codelineno-5-37" href="#__codelineno-5-37"></a>            <span class="p">)</span>
<a id="__codelineno-5-38" name="__codelineno-5-38" href="#__codelineno-5-38"></a>        <span class="p">)</span>
<a id="__codelineno-5-39" name="__codelineno-5-39" href="#__codelineno-5-39"></a><span class="n">model_evaluation</span> <span class="o">=</span> <span class="n">ModelEvaluation</span><span class="p">(</span>
<a id="__codelineno-5-40" name="__codelineno-5-40" href="#__codelineno-5-40"></a>        <span class="n">cores_per_worker</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>        <span class="c1"># ncores per GPU</span>
<a id="__codelineno-5-41" name="__codelineno-5-41" href="#__codelineno-5-41"></a>        <span class="n">max_walltime</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>          <span class="c1"># kill gracefully before end of slurm job</span>
<a id="__codelineno-5-42" name="__codelineno-5-42" href="#__codelineno-5-42"></a>        <span class="n">simulation_engine</span><span class="o">=</span><span class="s1">&#39;openmm&#39;</span><span class="p">,</span>
<a id="__codelineno-5-43" name="__codelineno-5-43" href="#__codelineno-5-43"></a>        <span class="n">gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-5-44" name="__codelineno-5-44" href="#__codelineno-5-44"></a>        <span class="n">parsl_provider</span><span class="o">=</span><span class="n">SlurmProvider</span><span class="p">(</span>
<a id="__codelineno-5-45" name="__codelineno-5-45" href="#__codelineno-5-45"></a>            <span class="n">partition</span><span class="o">=</span><span class="s1">&#39;gpu_rome_a100&#39;</span><span class="p">,</span>
<a id="__codelineno-5-46" name="__codelineno-5-46" href="#__codelineno-5-46"></a>            <span class="n">account</span><span class="o">=</span><span class="s1">&#39;2023_006&#39;</span><span class="p">,</span>
<a id="__codelineno-5-47" name="__codelineno-5-47" href="#__codelineno-5-47"></a>            <span class="n">nodes_per_block</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<a id="__codelineno-5-48" name="__codelineno-5-48" href="#__codelineno-5-48"></a>            <span class="n">cores_per_node</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
<a id="__codelineno-5-49" name="__codelineno-5-49" href="#__codelineno-5-49"></a>            <span class="n">init_blocks</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<a id="__codelineno-5-50" name="__codelineno-5-50" href="#__codelineno-5-50"></a>            <span class="n">max_blocks</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
<a id="__codelineno-5-51" name="__codelineno-5-51" href="#__codelineno-5-51"></a>            <span class="n">walltime</span><span class="o">=</span><span class="s1">&#39;12:00:00&#39;</span><span class="p">,</span>
<a id="__codelineno-5-52" name="__codelineno-5-52" href="#__codelineno-5-52"></a>            <span class="n">exclusive</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-5-53" name="__codelineno-5-53" href="#__codelineno-5-53"></a>            <span class="n">scheduler_options</span><span class="o">=</span><span class="s1">&#39;#SBATCH --gpus=1</span><span class="se">\n</span><span class="s1">#SBATCH --clusters=dodrio&#39;</span><span class="p">,</span> <span class="c1"># ask for a GPU!</span>
<a id="__codelineno-5-54" name="__codelineno-5-54" href="#__codelineno-5-54"></a>            <span class="n">launcher</span><span class="o">=</span><span class="n">launcher_gpu</span><span class="p">,</span>  <span class="c1"># binds GPU in container!</span>
<a id="__codelineno-5-55" name="__codelineno-5-55" href="#__codelineno-5-55"></a>            <span class="p">)</span>
<a id="__codelineno-5-56" name="__codelineno-5-56" href="#__codelineno-5-56"></a>        <span class="p">)</span>
<a id="__codelineno-5-57" name="__codelineno-5-57" href="#__codelineno-5-57"></a><span class="n">model_training</span> <span class="o">=</span> <span class="n">ModelTraining</span><span class="p">(</span>
<a id="__codelineno-5-58" name="__codelineno-5-58" href="#__codelineno-5-58"></a>        <span class="n">cores_per_worker</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
<a id="__codelineno-5-59" name="__codelineno-5-59" href="#__codelineno-5-59"></a>        <span class="n">gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-5-60" name="__codelineno-5-60" href="#__codelineno-5-60"></a>        <span class="n">max_walltime</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>          <span class="c1"># kill gracefully before end of slurm job</span>
<a id="__codelineno-5-61" name="__codelineno-5-61" href="#__codelineno-5-61"></a>        <span class="n">parsl_provider</span><span class="o">=</span><span class="n">SlurmProvider</span><span class="p">(</span>
<a id="__codelineno-5-62" name="__codelineno-5-62" href="#__codelineno-5-62"></a>            <span class="n">partition</span><span class="o">=</span><span class="s1">&#39;gpu_rome_a100&#39;</span><span class="p">,</span>
<a id="__codelineno-5-63" name="__codelineno-5-63" href="#__codelineno-5-63"></a>            <span class="n">account</span><span class="o">=</span><span class="s1">&#39;2023_006&#39;</span><span class="p">,</span>
<a id="__codelineno-5-64" name="__codelineno-5-64" href="#__codelineno-5-64"></a>            <span class="n">nodes_per_block</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<a id="__codelineno-5-65" name="__codelineno-5-65" href="#__codelineno-5-65"></a>            <span class="n">cores_per_node</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
<a id="__codelineno-5-66" name="__codelineno-5-66" href="#__codelineno-5-66"></a>            <span class="n">init_blocks</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<a id="__codelineno-5-67" name="__codelineno-5-67" href="#__codelineno-5-67"></a>            <span class="n">max_blocks</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
<a id="__codelineno-5-68" name="__codelineno-5-68" href="#__codelineno-5-68"></a>            <span class="n">walltime</span><span class="o">=</span><span class="s1">&#39;12:00:00&#39;</span><span class="p">,</span>
<a id="__codelineno-5-69" name="__codelineno-5-69" href="#__codelineno-5-69"></a>            <span class="n">exclusive</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-5-70" name="__codelineno-5-70" href="#__codelineno-5-70"></a>            <span class="n">scheduler_options</span><span class="o">=</span><span class="s1">&#39;#SBATCH --gpus=1</span><span class="se">\n</span><span class="s1">#SBATCH --clusters=dodrio&#39;</span><span class="p">,</span>
<a id="__codelineno-5-71" name="__codelineno-5-71" href="#__codelineno-5-71"></a>            <span class="n">launcher</span><span class="o">=</span><span class="n">launcher_gpu</span><span class="p">,</span>
<a id="__codelineno-5-72" name="__codelineno-5-72" href="#__codelineno-5-72"></a>            <span class="p">)</span>
<a id="__codelineno-5-73" name="__codelineno-5-73" href="#__codelineno-5-73"></a>        <span class="p">)</span>
<a id="__codelineno-5-74" name="__codelineno-5-74" href="#__codelineno-5-74"></a><span class="n">reference_evaluation</span> <span class="o">=</span> <span class="n">ReferenceEvaluation</span><span class="p">(</span>
<a id="__codelineno-5-75" name="__codelineno-5-75" href="#__codelineno-5-75"></a>        <span class="n">cores_per_worker</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
<a id="__codelineno-5-76" name="__codelineno-5-76" href="#__codelineno-5-76"></a>        <span class="n">max_walltime</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>            <span class="c1"># singlepoints should finish in less than 20 mins</span>
<a id="__codelineno-5-77" name="__codelineno-5-77" href="#__codelineno-5-77"></a>        <span class="n">parsl_provider</span><span class="o">=</span><span class="n">SlurmProvider</span><span class="p">(</span>
<a id="__codelineno-5-78" name="__codelineno-5-78" href="#__codelineno-5-78"></a>            <span class="n">partition</span><span class="o">=</span><span class="s1">&#39;cpu_milan&#39;</span><span class="p">,</span>
<a id="__codelineno-5-79" name="__codelineno-5-79" href="#__codelineno-5-79"></a>            <span class="n">account</span><span class="o">=</span><span class="s1">&#39;2022_050&#39;</span><span class="p">,</span>
<a id="__codelineno-5-80" name="__codelineno-5-80" href="#__codelineno-5-80"></a>            <span class="n">nodes_per_block</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<a id="__codelineno-5-81" name="__codelineno-5-81" href="#__codelineno-5-81"></a>            <span class="n">cores_per_node</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>      <span class="c1"># 1 reference evaluation per SLURM job</span>
<a id="__codelineno-5-82" name="__codelineno-5-82" href="#__codelineno-5-82"></a>            <span class="n">init_blocks</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<a id="__codelineno-5-83" name="__codelineno-5-83" href="#__codelineno-5-83"></a>            <span class="n">max_blocks</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
<a id="__codelineno-5-84" name="__codelineno-5-84" href="#__codelineno-5-84"></a>            <span class="n">walltime</span><span class="o">=</span><span class="s1">&#39;12:00:00&#39;</span><span class="p">,</span>
<a id="__codelineno-5-85" name="__codelineno-5-85" href="#__codelineno-5-85"></a>            <span class="n">exclusive</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-5-86" name="__codelineno-5-86" href="#__codelineno-5-86"></a>            <span class="n">scheduler_options</span><span class="o">=</span><span class="s1">&#39;#SBATCH --clusters=dodrio</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span>
<a id="__codelineno-5-87" name="__codelineno-5-87" href="#__codelineno-5-87"></a>            <span class="n">launcher</span><span class="o">=</span><span class="n">launcher_cpu</span><span class="p">,</span>
<a id="__codelineno-5-88" name="__codelineno-5-88" href="#__codelineno-5-88"></a>            <span class="p">)</span>
<a id="__codelineno-5-89" name="__codelineno-5-89" href="#__codelineno-5-89"></a>        <span class="p">)</span>
<a id="__codelineno-5-90" name="__codelineno-5-90" href="#__codelineno-5-90"></a>
<a id="__codelineno-5-91" name="__codelineno-5-91" href="#__codelineno-5-91"></a>
<a id="__codelineno-5-92" name="__codelineno-5-92" href="#__codelineno-5-92"></a><span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="n">path_internal</span><span class="p">):</span>
<a id="__codelineno-5-93" name="__codelineno-5-93" href="#__codelineno-5-93"></a>    <span class="n">definitions</span> <span class="o">=</span> <span class="p">[</span>
<a id="__codelineno-5-94" name="__codelineno-5-94" href="#__codelineno-5-94"></a>            <span class="n">default</span><span class="p">,</span>
<a id="__codelineno-5-95" name="__codelineno-5-95" href="#__codelineno-5-95"></a>            <span class="n">model_evaluation</span><span class="p">,</span>
<a id="__codelineno-5-96" name="__codelineno-5-96" href="#__codelineno-5-96"></a>            <span class="n">model_training</span><span class="p">,</span>
<a id="__codelineno-5-97" name="__codelineno-5-97" href="#__codelineno-5-97"></a>            <span class="n">reference_evaluation</span><span class="p">,</span>
<a id="__codelineno-5-98" name="__codelineno-5-98" href="#__codelineno-5-98"></a>            <span class="p">]</span>
<a id="__codelineno-5-99" name="__codelineno-5-99" href="#__codelineno-5-99"></a>    <span class="n">config</span> <span class="o">=</span> <span class="n">generate_parsl_config</span><span class="p">(</span>
<a id="__codelineno-5-100" name="__codelineno-5-100" href="#__codelineno-5-100"></a>            <span class="n">path_internal</span><span class="p">,</span>
<a id="__codelineno-5-101" name="__codelineno-5-101" href="#__codelineno-5-101"></a>            <span class="n">definitions</span><span class="p">,</span>
<a id="__codelineno-5-102" name="__codelineno-5-102" href="#__codelineno-5-102"></a>            <span class="n">use_work_queue</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-5-103" name="__codelineno-5-103" href="#__codelineno-5-103"></a>            <span class="n">parsl_max_idletime</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<a id="__codelineno-5-104" name="__codelineno-5-104" href="#__codelineno-5-104"></a>            <span class="n">parsl_retries</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<a id="__codelineno-5-105" name="__codelineno-5-105" href="#__codelineno-5-105"></a>            <span class="p">)</span>
<a id="__codelineno-5-106" name="__codelineno-5-106" href="#__codelineno-5-106"></a>    <span class="k">return</span> <span class="n">config</span><span class="p">,</span> <span class="n">definitions</span>
</code></pre></div>
Check out the <a href="https://github.com/molmod/psiflow/tree/main/configs">configs</a> directory for more example configurations.</p>
<h3 id="manual">Manual</h3>
<p>Containerized execution is of course optional; users are free to provide their own environments
in which psiflow tasks need to execute in case they want full control over the specific
versions of each of the pieces of software.
Parsl providers typically have an optional <code>worker_init</code> argument which can be used to 
activate specific Python environments or execute <code>module load</code> commands.</p>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.instant", "navigation.tracking", "navigation.indexes", "navigation.expand", "toc.integrate", "toc.follow"], "search": "../assets/javascripts/workers/search.74e28a9f.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.220ee61c.min.js"></script>
      
        
          <script src="../javascripts/mathjax.js"></script>
        
      
        
          <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        
      
        
          <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        
      
        
          <script src="../javascripts/katex.js"></script>
        
      
        
          <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/katex.min.js"></script>
        
      
        
          <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/contrib/auto-render.min.js"></script>
        
      
    
  </body>
</html>